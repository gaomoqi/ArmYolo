Model: FineTuneModel(
  (base_model): ImageJacobianNet(
    (fc1): Linear(in_features=6, out_features=60, bias=True)
    (fc4): Linear(in_features=60, out_features=4, bias=False)
    (leaky_relu1): LeakyReLU(negative_slope=0.01)
  )
  (new_layer_list): ModuleList(
    (0): Linear(in_features=12, out_features=64, bias=True)
    (1): Linear(in_features=64, out_features=64, bias=True)
    (2): Linear(in_features=64, out_features=12, bias=True)
  )
  (batch_norm_list): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (relu): LeakyReLU(negative_slope=0.01)
  (dropout): Dropout(p=0, inplace=False)
)
Base Model path: training_new_output/training_output_new_1/final_model.pt
Dataset path: cleaned_data/new_cleaned_data_10.csv
Number of epochs: 200
Batch size: 128
Learning rate: 0.005
Loss function: L1Loss()
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.005
    maximize: False
    weight_decay: 0
)
Scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x76ce51eadeb0>
